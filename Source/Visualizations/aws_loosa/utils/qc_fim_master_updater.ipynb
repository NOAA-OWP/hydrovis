{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4258f80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nodejs\n",
      "  Downloading nodejs-0.1.1.tar.gz (2.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting geopandas\n",
      "  Downloading geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\n",
      "     |████████████████████████████████| 994 kB 25.0 MB/s            \n",
      "\u001b[?25hCollecting contextily\n",
      "  Downloading contextily-1.3.0-py3-none-any.whl (16 kB)\n",
      "Collecting optional-django==0.1.0\n",
      "  Downloading optional-django-0.1.0.tar.gz (9.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyproj>=2.2.0\n",
      "  Downloading pyproj-3.0.1-cp36-cp36m-manylinux2010_x86_64.whl (6.5 MB)\n",
      "     |████████████████████████████████| 6.5 MB 55.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from geopandas) (1.1.5)\n",
      "Collecting shapely>=1.6\n",
      "  Downloading Shapely-1.8.5.post1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
      "     |████████████████████████████████| 2.0 MB 52.7 MB/s            \n",
      "\u001b[?25hCollecting fiona>=1.8\n",
      "  Downloading Fiona-1.8.22-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
      "     |████████████████████████████████| 16.6 MB 46.8 MB/s            \n",
      "\u001b[?25hCollecting rasterio\n",
      "  Downloading rasterio-1.2.10-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (19.2 MB)\n",
      "     |████████████████████████████████| 19.2 MB 64.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from contextily) (3.3.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from contextily) (2.26.0)\n",
      "Collecting mercantile\n",
      "  Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from contextily) (1.0.1)\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from contextily) (8.4.0)\n",
      "Collecting geopy\n",
      "  Downloading geopy-2.2.0-py3-none-any.whl (118 kB)\n",
      "     |████████████████████████████████| 118 kB 73.8 MB/s            \n",
      "\u001b[?25hCollecting contextily\n",
      "  Downloading contextily-1.2.0-py3-none-any.whl (16 kB)\n",
      "  Downloading contextily-1.1.0-py3-none-any.whl (24 kB)\n",
      "Collecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: six>=1.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from fiona>=1.8->geopandas) (2021.5.30)\n",
      "Collecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Requirement already satisfied: click>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from fiona>=1.8->geopandas) (49.6.0.post20210108)\n",
      "Requirement already satisfied: attrs>=17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from fiona>=1.8->geopandas) (20.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.24.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.24.0->geopandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.24.0->geopandas) (1.19.5)\n",
      "Collecting geographiclib<2,>=1.49\n",
      "  Downloading geographiclib-1.52-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->contextily) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->contextily) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->contextily) (0.10.0)\n",
      "Collecting affine\n",
      "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
      "Collecting snuggs>=1.4.1\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->contextily) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->contextily) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->contextily) (2.0.9)\n",
      "Building wheels for collected packages: nodejs, optional-django\n",
      "  Building wheel for nodejs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nodejs: filename=nodejs-0.1.1-py3-none-any.whl size=3492 sha256=87c325b830bd271ad5415ea3d4cec236a1504a226839d112cace422895284003\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e0/2f/be/4ee779e16832b901c856255265149d584e14e519d32e7875c5\n",
      "  Building wheel for optional-django (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for optional-django: filename=optional_django-0.1.0-py3-none-any.whl size=9980 sha256=4494f232c637ab02da4433378a9e7b1493964a09fcd2800070cd399bd5044741\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/d9/41/fa/ec371df00324a29592bd9f10c85d3d766507fc4aa7bb5ccfc1\n",
      "Successfully built nodejs optional-django\n",
      "Installing collected packages: snuggs, munch, geographiclib, cligj, click-plugins, affine, shapely, rasterio, pyproj, optional-django, mercantile, geopy, fiona, nodejs, geopandas, contextily\n",
      "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 contextily-1.1.0 fiona-1.8.22 geographiclib-1.52 geopandas-0.9.0 geopy-2.2.0 mercantile-1.2.1 munch-2.5.0 nodejs-0.1.1 optional-django-0.1.0 pyproj-3.0.1 rasterio-1.2.10 shapely-1.8.5.post1 snuggs-1.4.7\n"
     ]
    }
   ],
   "source": [
    "!pip install nodejs geopandas contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "545acaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qc_fim_data/flow_based_catfim.csv\n",
      "--> Downloading hydrovis-ti-deployment-us-east-1/qc_fim_data/flow_based_catfim.csv to brad_data/qc_fim_data/flow_based_catfim.csv\n",
      "Reading file...\n",
      "File read.\n",
      "Retrieving values for *\n",
      "Loading data into DB...\n",
      "Dataframe shape\n",
      "12854\n",
      "Chunk loading...\n",
      "list_df len\n",
      "1\n",
      "12854\n",
      "Dropping reference.flow_based_catfim if it exists\n",
      "Getting sql to create table\n",
      "CREATE TABLE reference.flow_based_catfim (\n",
      "\"oid\" INTEGER,\n",
      "  \"ahps_lid\" TEXT,\n",
      "  \"magnitude\" TEXT,\n",
      "  \"version\" TEXT,\n",
      "  \"huc8\" TEXT,\n",
      "  \"interval_stage\" DOUBLE PRECISION,\n",
      "  \"name\" TEXT,\n",
      "  \"wfo\" TEXT,\n",
      "  \"rfc\" TEXT,\n",
      "  \"state\" TEXT,\n",
      "  \"county\" TEXT,\n",
      "  \"q\" DOUBLE PRECISION,\n",
      "  \"q_uni\" TEXT,\n",
      "  \"q_src\" TEXT,\n",
      "  \"stage\" DOUBLE PRECISION,\n",
      "  \"stage_uni\" TEXT,\n",
      "  \"s_src\" TEXT,\n",
      "  \"wrds_time\" TEXT,\n",
      "  \"nrldb_time\" TEXT,\n",
      "  \"nwis_time\" TEXT,\n",
      "  \"lat\" DOUBLE PRECISION,\n",
      "  \"lon\" DOUBLE PRECISION,\n",
      "  \"viz\" TEXT,\n",
      "  \"geom\" GEOMETRY(Geometry,3857)\n",
      ")\n",
      "Creating reference.flow_based_catfim\n",
      "Adding data to reference.flow_based_catfim\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from helper_functions.shared_functions import *\n",
    "import boto3\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# os.environ['EGIS_DB_HOST'] = \"hv-ti-egis-rds-pg-egdb.c4vzypepnkx3.us-east-1.rds.amazonaws.com\"  #TI DB\n",
    "os.environ['EGIS_DB_HOST'] = \"hv-ti-egis-rds-pg-egdb.c4vzypepnkx3.us-east-1.rds.amazonaws.com\"  #Dev DB\n",
    "os.environ['EGIS_DB_DATABASE'] = \"hydrovis\"\n",
    "os.environ['EGIS_DB_USERNAME'] = \"hydrovis\"\n",
    "os.environ['EGIS_DB_PASSWORD'] = \"hardwork123donehere\"\n",
    "\n",
    "db_type = \"egis\"\n",
    "db_engine = get_db_engine(db_type)\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define bucket and parent directories.\n",
    "bucket = \"hydrovis-ti-deployment-us-east-1\"\n",
    "parent_directory = \"qc_fim_data\"\n",
    "local_download_parent_directory = f'brad_data/qc_fim_data'\n",
    "\n",
    "#file_handles = ['flow_based_catfim.csv', 'flow_based_catfim_sites.csv',\n",
    "#               'stage_based_catfim.csv', 'stage_based_catfim_sites.csv']\n",
    "\n",
    "#file_handles = ['fim_performance_points.csv', 'fim_performance_polys.csv']\n",
    "\n",
    "#file_handles = ['fim_performance_catchments.csv']\n",
    "\n",
    "#file_handles = ['stage_based_catfim_sites.csv']\n",
    "\n",
    "file_handles = ['flow_based_catfim.csv']\n",
    "#file_handles = ['stage_based_catfim_sites.csv']\n",
    "\n",
    "for file_handle in file_handles:\n",
    "    # Define path to file to download and its local download path, the download.\n",
    "    filename = f\"{parent_directory}/{file_handle}\"\n",
    "    print(filename)\n",
    "    local_download_path = os.path.join(local_download_parent_directory, f'{file_handle}')\n",
    "    print(f\"--> Downloading {bucket}/{filename} to {local_download_path}\")\n",
    "    #s3.download_file(bucket, filename, local_download_path)\n",
    "    \n",
    "    #  -- Open file and reformat -- #\n",
    "    print(\"Reading file...\")\n",
    "    df = pd.read_csv(local_download_path)\n",
    "    print(\"File read.\")\n",
    "    # Rename headers.\n",
    "    if file_handle == 'fim_performance_points.csv':\n",
    "        df = df.rename(columns={'Unnamed: 0': 'oid', 'geometry': 'geom'})\n",
    "    else:\n",
    "        df = df.rename(columns={'Unnamed: 0': 'oid', 'geometry': 'geom', 'huc':'huc8'})\n",
    "        \n",
    "    if file_handle == 'stage_based_catfim.csv':\n",
    "        pass\n",
    "        # Simplify and clean up status messages before loading into DB\n",
    "    if file_handle == 'fim_performance_catchments.csv':\n",
    "        #df = df.drop('valid', axis=1)\n",
    "        print(df.shape)\n",
    " #       df.insert(0, 'oid', range(0, len(df)))\n",
    "    # Convert all field names to lowercase (needed for ArcGIS Pro).\n",
    "    df.columns= df.columns.str.lower()\n",
    "\n",
    "    # Remove sites that are in derived.ahps_restricted_sites\n",
    "    if \"catfim\" in file_handle:\n",
    "        restricted_sites_df = get_db_values(\"derived.ahps_restricted_sites\", \"*\")\n",
    "        restricted_dict = restricted_sites_df.to_dict('records')\n",
    "        \n",
    "        # Change 'mapped' to 'no' if sites are present in restricted_sites_df\n",
    "        for site in restricted_dict:\n",
    "            nws_lid = site['nws_lid'].lower()\n",
    "            if \"sites\" in file_handle:\n",
    "                print(True)\n",
    "                print(nws_lid)\n",
    "                df.loc[df.ahps_lid==nws_lid, 'mapped'] = 'no'\n",
    "                df.loc[df.ahps_lid==nws_lid, 'status'] = site['restricted_reason']\n",
    "                print(df.loc[df.ahps_lid==nws_lid]['status'])\n",
    "            else:\n",
    "                df.loc[df.ahps_lid==nws_lid, 'viz'] = 'no'\n",
    "    \n",
    "        # Enforce data types on df before loading in DB (TODO: need to create special cases for each layer).\n",
    "    if file_handle == 'fim_performance_points.csv':\n",
    "        df = df.astype({'huc': 'str'})\n",
    "    else:\n",
    "        df = df.astype({'huc8': 'str'})\n",
    "    df = df.fillna(0)\n",
    "    try:\n",
    "        df = df.astype({'feature_id': 'int'})\n",
    "        df = df.astype({'feature_id': 'str'})\n",
    "    except KeyError:  # If there is no feature_id field\n",
    "        pass\n",
    "    try:\n",
    "        df = df.astype({'nwm_seg': 'int'})\n",
    "        df = df.astype({'nwm_seg': 'str'})\n",
    "    except KeyError:  # If there is no nwm_seg field\n",
    "        pass\n",
    "    try:\n",
    "        df = df.astype({'usgs_gage': 'int'})\n",
    "        df = df.astype({'usgs_gage': 'str'})\n",
    "    except KeyError:  # If there is no usgs_gage field\n",
    "        pass\n",
    "        \n",
    "    # zfill HUC8 field.\n",
    "    if file_handle == 'fim_performance_points.csv':\n",
    "        df['huc'] = df['huc'].apply(lambda x: x.zfill(8))\n",
    "    else:\n",
    "        df['huc8'] = df['huc8'].apply(lambda x: x.zfill(8))\n",
    "    \n",
    "    if file_handle in ['flow_based_catfim_sites.csv', 'stage_based_catfim_sites.csv']:\n",
    "        df = df.astype({'nws_data_rfc_forecast_point': 'str'})\n",
    "        df = df.astype({'nws_data_rfc_defined_fcst_point': 'str'})\n",
    "        df = df.astype({'nws_data_riverpoint': 'str'})\n",
    "        \n",
    "    # Upload df to database.\n",
    "    stripped_layer_name = file_handle.replace(\".csv\", \"\")\n",
    "    table_name = \"reference.\" + stripped_layer_name\n",
    "    print(\"Loading data into DB...\")\n",
    "    \n",
    "    print(\"Dataframe shape\")\n",
    "    print(df.shape[0])\n",
    "    \n",
    "    # Chunk load data into DB\n",
    "    if file_handle in ['fim_performance_catchments.csv', 'stage_based_catfim.csv', 'flow_based_catfim.csv']:\n",
    "        print(\"Chunk loading...\")\n",
    "        # Create list of df chunks\n",
    "        n = 100000  #chunk row size\n",
    "        list_df = [df[i:i+n] for i in range(0,df.shape[0],n)]\n",
    "        print(\"list_df len\")\n",
    "        print(len(list_df))\n",
    "        \n",
    "        # Load the first chunk into the DB as a new table\n",
    "        first_chunk_df = list_df[0]\n",
    "        print(first_chunk_df.shape[0])\n",
    "        load_df_into_db(table_name, db_engine, first_chunk_df, epsg=3857, drop_first=True)\n",
    "        \n",
    "        # Load remaining chunks into newly created table\n",
    "        for remaining_chunk in list_df[1:]:\n",
    "            print(remaining_chunk.shape[0])\n",
    "            load_df_into_db(table_name, db_engine, remaining_chunk, epsg=3857, drop_first=False)\n",
    "        db_engine.execute(f'CREATE INDEX ON reference.{stripped_layer_name} USING GIST (geom);')\n",
    "        \n",
    "    else:\n",
    "        load_df_into_db(table_name, db_engine, df, epsg=3857, drop_first=True)\n",
    "        db_engine.execute(f'CREATE INDEX ON reference.{stripped_layer_name} USING GIST (geom);')\n",
    "        \n",
    "    if file_handle == 'fim_performance_catchments.csv':\n",
    "        print(\"Making valid...\")\n",
    "        make_valid_sql = f\"\"\"\n",
    "\n",
    "        ALTER TABLE reference.fim_performance_catchments\n",
    "          ADD COLUMN geom_invalid geometry\n",
    "          DEFAULT NULL;\n",
    "\n",
    "        UPDATE reference.fim_performance_catchments\n",
    "          SET geom = ST_MakeValid(geom),\n",
    "              geom_invalid = geom\n",
    "          WHERE NOT ST_IsValid(geom);\n",
    "          \"\"\"\n",
    "\n",
    "        db_engine.execute(make_valid_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ff541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   oid ahps_lid usgs_gage  nwm_seg      huc8 mapped  \\\n",
      "0    0    00brd         0  8211323  18060005    yes   \n",
      "1    1    00rdr         0  8200819  18060005    yes   \n",
      "2    2    brdc1  11150500  8211251  18060005    yes   \n",
      "3    3    chlc1  11152300  8200795  18060005     no   \n",
      "4    4    kcyc1  11151300  8205487  18060005    yes   \n",
      "5    5    lwdc1  11149900  8210533  18060005    yes   \n",
      "\n",
      "                                              status  \\\n",
      "0                  record is missing calculated flow   \n",
      "1                     all calculated flows available   \n",
      "2                  record is missing calculated flow   \n",
      "3                           missing calculated flows   \n",
      "4  minor is missing calculated flow, major is mis...   \n",
      "5  minor is missing calculated flow, major is mis...   \n",
      "\n",
      "                                           geom  \n",
      "0  POINT (-13467864.90530122 4290726.437706408)  \n",
      "1  POINT (-13550921.61426519 4376566.834692953)  \n",
      "2  POINT (-13455052.32257835 4291027.211735288)  \n",
      "3  POINT (-13530815.71122726 4377061.915540783)  \n",
      "4  POINT (-13477039.20218417 4337563.577787813)  \n",
      "5  POINT (-13479482.23086107 4286407.680827582)  \n"
     ]
    }
   ],
   "source": [
    "print(df[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12516ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fim_performance...\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(psycopg2.IntegrityError) duplicate key value violates unique constraint \"services_pkey\"\nDETAIL:  Key (service)=(fim_performance) already exists.\n\n[SQL: \n    INSERT INTO admin.services(\n    service, folder, configuration, summary, description, tags, credits, run, feature_service, server, fim_service)\n    VALUES ('fim_performance', 'eval', 'reference', 'Height Above Nearest Drainage (HAND) Flood Inundation Mapping (FIM) Performance at HUC8s and AHPS locations.', 'Depicts FIM prediction skill metrics at HUC8s and AHPS locations. Metrics computed through static comparison of benchmark maps to HAND maps at specific magnitudes, e.g. 100yr, 500yr, Action, Minor, Moderate, Major. Metrics reported as Critical Success Index (CSI), True Positive Rate (TPR), False Alarm Ratio (FAR), and Probability Not Detected (PND). For a description of how metrics are computed, see https://github.com/NOAA-OWP/inundation-mapping/wiki/Evaluating-HAND-Performance. Benchmark sources include FEMA Base Level Engineering, AHPS, and Iowa Flood Center. This is not a forecast service.', 'performance, skill, csi, flood, hand, fim, inundation, height, above, nearest, drainage, ahps, usgs', 'National Water Model, NOAA/NWS National Water Center, Advanced Hydrologic Prediction Service, USGS, Iowa Flood Center, RAS2FIM', false, false, 'server', false);\n    ]\n(Background on this error at: http://sqlalche.me/e/13/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1266\u001b[0m                     self.dialect.do_execute_no_params(\n\u001b[0;32m-> 1267\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m                     )\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute_no_params\u001b[0;34m(self, cursor, statement, context)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: duplicate key value violates unique constraint \"services_pkey\"\nDETAIL:  Key (service)=(fim_performance) already exists.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-396e3d21e289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mVALUES\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'{service_name}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{folder}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{configuration}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{summary}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{description}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{tags}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{credits}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'server'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mrun_sql_in_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"viz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/helper_functions/shared_functions.py\u001b[0m in \u001b[0;36mrun_sql_in_db\u001b[0;34m(sql, db_type, return_geodataframe)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_geodataframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_postgis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         )\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m         return self.connectable.execution_options(no_parameters=True).execute(\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m         )\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   2233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2234\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contextual_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \"\"\"\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_text\u001b[0;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1317\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m             )\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m                 util.raise_(\n\u001b[0;32m-> 1511\u001b[0;31m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m                 )\n\u001b[1;32m   1513\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m                     self.dialect.do_execute_no_params(\n\u001b[0;32m-> 1267\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m                     )\n\u001b[1;32m   1269\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute_no_params\u001b[0;34m(self, cursor, statement, context)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_disconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (psycopg2.IntegrityError) duplicate key value violates unique constraint \"services_pkey\"\nDETAIL:  Key (service)=(fim_performance) already exists.\n\n[SQL: \n    INSERT INTO admin.services(\n    service, folder, configuration, summary, description, tags, credits, run, feature_service, server, fim_service)\n    VALUES ('fim_performance', 'eval', 'reference', 'Height Above Nearest Drainage (HAND) Flood Inundation Mapping (FIM) Performance at HUC8s and AHPS locations.', 'Depicts FIM prediction skill metrics at HUC8s and AHPS locations. Metrics computed through static comparison of benchmark maps to HAND maps at specific magnitudes, e.g. 100yr, 500yr, Action, Minor, Moderate, Major. Metrics reported as Critical Success Index (CSI), True Positive Rate (TPR), False Alarm Ratio (FAR), and Probability Not Detected (PND). For a description of how metrics are computed, see https://github.com/NOAA-OWP/inundation-mapping/wiki/Evaluating-HAND-Performance. Benchmark sources include FEMA Base Level Engineering, AHPS, and Iowa Flood Center. This is not a forecast service.', 'performance, skill, csi, flood, hand, fim, inundation, height, above, nearest, drainage, ahps, usgs', 'National Water Model, NOAA/NWS National Water Center, Advanced Hydrologic Prediction Service, USGS, Iowa Flood Center, RAS2FIM', false, false, 'server', false);\n    ]\n(Background on this error at: http://sqlalche.me/e/13/gkpj)"
     ]
    }
   ],
   "source": [
    "from helper_functions.shared_functions import *\n",
    "from brad_data.variables import service_desc_dict\n",
    "\n",
    "os.environ['VIZ_DB_USERNAME'] = \"viz_proc_admin_rw_user\"\n",
    "os.environ['VIZ_DB_PASSWORD'] = \"QLQW31ZxL0CuE78Rm1lvjYTWg\"\n",
    "\n",
    "for service_name in service_desc_dict:\n",
    "    print(\"Updating \" + service_name + \"...\")\n",
    "    folder = service_desc_dict[service_name]['folder']\n",
    "    configuration = service_desc_dict[service_name]['configuration']\n",
    "    summary = service_desc_dict[service_name]['summary']\n",
    "    description = service_desc_dict[service_name]['description']\n",
    "    tags = service_desc_dict[service_name]['tags']\n",
    "    credits = service_desc_dict[service_name]['credits']\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    INSERT INTO admin.services(\n",
    "    service, folder, configuration, summary, description, tags, credits, run, feature_service, server, fim_service)\n",
    "    VALUES ('{service_name}', '{folder}', '{configuration}', '{summary}', '{description}', '{tags}', '{credits}', false, false, 'server', false)\n",
    "    \"\"\"\n",
    "    run_sql_in_db(sql, db_type=\"viz\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6034175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4148add",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
