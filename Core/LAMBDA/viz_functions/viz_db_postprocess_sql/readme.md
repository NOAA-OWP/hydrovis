The postprocess_sql lambda function is a generalized lightweight lambda function used throughout VPP pipelines to execute SQL on a specified database (PostgreSQL RDS or Redshift)
It is typically used for operations like:
    - Ingest prep: Truncate a table and delete indicies prior to ingesting new data. Create a table if it doesn't exist yet.
    - Ingest finish: Rebuild indicies after ingest.
    - Database transformations: Query and/or aggregate ingested data into new table for a map service
    - Various steps of FIM Workflows (details below): With the implementation of FIM Caching to a Redshift Data Warehouse in HydroVIS version 2.2(?), this function can now be used to execute template SQL files as well. The template to use is defined by the input parameters in the step function, and generally does one of these things:
        - Create a table if it doesn't exist
        - Truncate a inundation table for a new pipeline run
        - Copy data from RDS to Redshift or vice versa (via Foreign Data Wrappers and External Schemas)
        - Data transformations / aggregations.

############################################# FIM Workflow ##############################################  
The following database operations are taken below to process FIM, largely via the fim_caching_templates sql files in this lambda function
0. Create four tables, if they don't already exist, on both RDS and Redshift. These tables replicate the schema of the HAND cache on Redshift, and are truncated and re-populated as part of each FIM run:
    - ingest.{fim_config}_flows                 - this is a version of max_flows, with fim crosswalk columns added, as well as filtering for hight water threshold
    - ingest.{fim_config}                       - this is the fim table, but without geometry
    - ingest.{fim_config}_geo                   - this is the geometries for the fim table (one-to-many, since we're subdividing to keep geometries small for Redshift)
    - ingest.{fim_config}_zero_stage            - this table holds all of the fim features (hydro_table, feature_id, huc8, branch combinations) that have zero or NaN stage at the current discharge value
    - ingest.{fim_config}_geo_view (RDS only)   - this view subdivides the newly polygons in the inundation_geo table (because Redshift has a limit on the size of geometries)
    - publish.{fim_config} (RDS only)           - This is the finished publish table that gets copied to the EGIS service
1. Populate the FIM flows table on RDS (from max_flows with some joins), then copy it to Redshift
2. Query the HAND Cache on Redshift
    a. Query the HAND cache on Redshift, joining to the just-populated flows table, to populate the inundation, inundation_geo, and inundation_zero_stage tables on Redshift
3. Populate the inundation tables on RDS
    a. Prioritize Ras2FIM by querying the Ras2FIM cache on RDS first #TODO
    b. Copy the FIM tables on Redshift (which were just populated from the HAND cache in 2a) into the inundation tables on RDS (skipping any records that were already added from Ras2FIM)
    c. HAND processing for any FIM features remaining in the inundation flows table, that have not been added to the inundation table from Ras2FIM or the HAND cache (not done here, but administered by the fim_data_prep lambda function
4. Generate publish.inundation table on RDS, and copy it to the EGIS (done via the update_egis_data function)
    a. We can use a template to do this generically for most inland inundation configurations (e.g. NWM)
5. Add any newly generated HAND features in this run into the Redshift HAND cache ( #TODO: it would be good to figure out how to do this in parallel outside of the fim_config map, so that this doesn't hold things up).
    a. Insert records from the RDS inundation, inundation_geo, and inundation_zero_stage tables/view into the Redshift HAND cache tables, only taking records generated by HAND Processing, and which the primary key does not already exist (hydro_id, feature_id, huc8, branch, rc_stage_ft)
        